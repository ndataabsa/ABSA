{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf594f6-7c14-42bc-ae6b-73093770a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "from transformers import AdamW, T5Tokenizer\n",
    "from mvp.t5 import MyT5ForConditionalGeneration\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from mvp.data_utils import *\n",
    "from mvp.eval_utils import *\n",
    "from mvp.process import *\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875ff26f-a3af-47e6-982f-ae79f03a860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: mvp\n",
      "output path: /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n"
     ]
    }
   ],
   "source": [
    "# setting args\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.path = '/home/elicer/ABSA'\n",
    "        self.data_path = f'{self.path}/data'\n",
    "        self.method = 'mvp' # task \n",
    "        self.paraphrase = False # task \n",
    "        self.task = 'asqp' # task \n",
    "        self.dataset = 'rest16' # data \n",
    "        self.eval_data_split = 'test' # test or dev\n",
    "        self.top_k = 5\n",
    "        self.ctrl_token = \"post\"\n",
    "        self.data_ratio = 1.0\n",
    "        self.model_name_or_path = 't5-base' # used base model\n",
    "        self.load_ckpt_name = None # 사전 훈련된 모델의 체크포인트 파일로드 \n",
    "        self.do_train = False # train or not\n",
    "        self.do_inference = True # inference or not\n",
    "        self.max_seq_length = 200 # 입력 시퀀스 최대 길이\n",
    "        self.n_gpu = 1 # gpu 개수\n",
    "        self.train_batch_size = 16\n",
    "        self.eval_batch_size = 64\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 1e-4\n",
    "        self.num_train_epochs = 20\n",
    "        self.seed = 25\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.warmup_steps = 0.0\n",
    "        self.multi_path = False\n",
    "        self.num_path = 1\n",
    "        self.beam_size = 1\n",
    "        self.save_top_k = 1\n",
    "        self.check_val_every_n_epoch = 10\n",
    "        self.single_view_type = \"rank\"\n",
    "        self.sort_label = False\n",
    "        self.load_path_cache = False\n",
    "        self.lowercase = False\n",
    "        self.multi_task = False\n",
    "        self.constrained_decode = False\n",
    "        self.agg_strategy = 'vote'\n",
    "\n",
    "def init_args():\n",
    "    args = Args()\n",
    "\n",
    "    if args.task == 'asqp':\n",
    "        args.lowercase = True\n",
    "\n",
    "    if args.method == 'dlo':\n",
    "        args.top_k = 1\n",
    "        args.single_view_type = \"heuristic\"\n",
    "        args.agg_strategy = 'heuristic'\n",
    "\n",
    "    if args.method == 'paraphrase':\n",
    "        args.paraphrase = True\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/{args.ctrl_token}_data{args.data_ratio}'\n",
    "    else:\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/top_{args.top_k}_{args.ctrl_token}_data{args.data_ratio}'\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        #os.mkdir(args.output_dir)\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "args = init_args()\n",
    "\n",
    "print('method:', args.method)\n",
    "print('output path:', args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a43532-453c-48e7-91f5-290a4ec3b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Fine tune a pre-trained T5 model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, tfm_model, tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['tfm_model'])\n",
    "        self.config = config\n",
    "        self.model = tfm_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                decoder_input_ids=None,\n",
    "                decoder_attention_mask=None,\n",
    "                labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(input_ids=batch[\"source_ids\"],\n",
    "                       attention_mask=batch[\"source_mask\"],\n",
    "                       labels=lm_labels,\n",
    "                       decoder_attention_mask=batch['target_mask'])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        # get f1\n",
    "        outs = self.model.generate(input_ids=batch['source_ids'],\n",
    "                                   attention_mask=batch['source_mask'],\n",
    "                                   max_length=self.config.max_seq_length,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   num_beams=1)\n",
    "\n",
    "        dec = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in outs.sequences\n",
    "        ]\n",
    "        target = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in batch[\"target_ids\"]\n",
    "        ]\n",
    "        if args.paraphrase:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        else:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        f1 = torch.tensor(scores['f1'], dtype=torch.float64)\n",
    "\n",
    "        # get loss\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\",\n",
    "                     loss,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "            self.log(f\"{stage}_f1\",\n",
    "                     f1,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Prepare optimizer and schedule (linear warmup and decay) \"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.config.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.config.learning_rate,\n",
    "                          eps=self.config.adam_epsilon)\n",
    "        scheduler = {\n",
    "            \"scheduler\":\n",
    "            get_linear_schedule_with_warmup(optimizer,\n",
    "                                            **self.config.lr_scheduler_init),\n",
    "            \"interval\":\n",
    "            \"step\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"load training data.\")\n",
    "        train_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                    task_name=args.task,\n",
    "                                    data_name=args.dataset,\n",
    "                                    data_type=\"train\",\n",
    "                                    top_k=self.config.top_k,\n",
    "                                    args=self.config,\n",
    "                                    max_len=self.config.max_seq_length)\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.train_batch_size,\n",
    "            drop_last=True\n",
    "            if args.data_ratio > 0.3 else False, # don't drop on few-shot\n",
    "            shuffle=True,\n",
    "            num_workers=2)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                  task_name=args.task,\n",
    "                                  data_name=args.dataset,\n",
    "                                  data_type=\"dev\",\n",
    "                                  top_k=self.config.num_path,\n",
    "                                  args=self.config,\n",
    "                                  max_len=self.config.max_seq_length)\n",
    "        return DataLoader(val_dataset,\n",
    "                          batch_size=self.config.eval_batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def rindex(_list, _value):\n",
    "        return len(_list) - _list[::-1].index(_value) - 1\n",
    "\n",
    "    def prefix_allowed_tokens_fn(self, task, data_name, source_ids, batch_id,\n",
    "                                 input_ids):\n",
    "        \"\"\"\n",
    "        Constrained Decoding\n",
    "        # ids = self.tokenizer(\"text\", return_tensors='pt')['input_ids'].tolist()[0]\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./force_tokens.json'):\n",
    "            dic = {\"cate_tokens\":{}, \"all_tokens\":{}, \"sentiment_tokens\":[], 'special_tokens':[]}\n",
    "            for task in force_words.keys():\n",
    "                dic[\"all_tokens\"][task] = {}\n",
    "                for dataset in force_words[task].keys():\n",
    "                    cur_list = force_words[task][dataset]\n",
    "                    tokenize_res = []\n",
    "                    for w in cur_list:\n",
    "                        tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "                    dic[\"all_tokens\"][task][dataset] = tokenize_res\n",
    "            for k,v in cate_list.items():\n",
    "                tokenize_res = []\n",
    "                for w in v:\n",
    "                    tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "                dic[\"cate_tokens\"][k] = tokenize_res\n",
    "            sp_tokenize_res = []\n",
    "            for sp in ['great', 'ok', 'bad']:\n",
    "                sp_tokenize_res.extend(self.tokenizer(sp, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "            for task in force_words.keys():\n",
    "                dic['sentiment_tokens'][task] = sp_tokenize_res\n",
    "            dic['sentiment_tokens'] = sp_tokenize_res\n",
    "            special_tokens_tokenize_res = []\n",
    "            for w in ['[O','[A','[S','[C','[SS']:\n",
    "                special_tokens_tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "            special_tokens_tokenize_res = [r for r in special_tokens_tokenize_res if r != 784]\n",
    "            dic['special_tokens'] = special_tokens_tokenize_res\n",
    "            import json\n",
    "            with open(\"force_tokens.json\", 'w') as f:\n",
    "                json.dump(dic, f, indent=4)\n",
    "\n",
    "        to_id = {\n",
    "            'OT': [667],\n",
    "            'AT': [188],\n",
    "            'SP': [134],\n",
    "            'AC': [254],\n",
    "            'SS': [4256],\n",
    "            'EP': [8569],\n",
    "            '[': [784],\n",
    "            ']': [908],\n",
    "            'it': [34],\n",
    "            'null': [206,195]\n",
    "        }\n",
    "\n",
    "        left_brace_index = (input_ids == to_id['['][0]).nonzero()\n",
    "        right_brace_index = (input_ids == to_id[']'][0]).nonzero()\n",
    "        num_left_brace = len(left_brace_index)\n",
    "        num_right_brace = len(right_brace_index)\n",
    "        last_right_brace_pos = right_brace_index[-1][\n",
    "            0] if right_brace_index.nelement() > 0 else -1\n",
    "        last_left_brace_pos = left_brace_index[-1][\n",
    "            0] if left_brace_index.nelement() > 0 else -1\n",
    "        cur_id = input_ids[-1]\n",
    "\n",
    "        if cur_id in to_id['[']:\n",
    "            return force_tokens['special_tokens']\n",
    "        elif cur_id in to_id['AT'] + to_id['OT'] + to_id['EP'] + to_id['SP'] + to_id['AC']:  \n",
    "            return to_id[']']  \n",
    "        elif cur_id in to_id['SS']:  \n",
    "            return to_id['EP'] \n",
    "\n",
    "        # get cur_term\n",
    "        if last_left_brace_pos == -1:\n",
    "            return to_id['['] + [1]   # start of sentence: [\n",
    "        elif (last_left_brace_pos != -1 and last_right_brace_pos == -1) \\\n",
    "            or last_left_brace_pos > last_right_brace_pos:\n",
    "            return to_id[']']  # ]\n",
    "        else:\n",
    "            cur_term = input_ids[last_left_brace_pos + 1]\n",
    "\n",
    "        ret = []\n",
    "        if cur_term in to_id['SP']:  # SP\n",
    "            ret = force_tokens['sentiment_tokens'][task]\n",
    "        elif cur_term in to_id['AT']:  # AT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task != 'aste':  \n",
    "                force_list.extend(to_id['it'] + [1])  \n",
    "            ret = force_list  \n",
    "        elif cur_term in to_id['SS']:\n",
    "            ret = [3] + to_id[']'] + [1]\n",
    "        elif cur_term in to_id['AC']:  # AC\n",
    "            ret = force_tokens['cate_tokens'][data_name]\n",
    "        elif cur_term in to_id['OT']:  # OT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task == \"acos\":\n",
    "                force_list.extend(to_id['null'])  # null\n",
    "            ret = force_list\n",
    "        else:\n",
    "            raise ValueError(cur_term)\n",
    "\n",
    "        if num_left_brace == num_right_brace:\n",
    "            ret = set(ret)\n",
    "            ret.discard(to_id[']'][0]) # remove ]\n",
    "            for w in force_tokens['special_tokens']:\n",
    "                ret.discard(w)\n",
    "            ret = list(ret)\n",
    "        elif num_left_brace > num_right_brace:\n",
    "            ret += to_id[']'] \n",
    "        else:\n",
    "            raise ValueError\n",
    "        ret.extend(to_id['['] + [1]) # add [\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106a7f84-fefc-4f18-9c33-bd885a25617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:00<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 515, 2: 127, 3: 22, 4: 3, 5: 1})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 852, hit: 337\n",
      "\n",
      "dev_zero_1 vote precision: 39.55 recall: 34.07 F1 = 36.61\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:00<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 525, 2: 120, 3: 20, 4: 3})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 837, hit: 333\n",
      "\n",
      "dev_zero_2 vote precision: 39.78 recall: 33.67 F1 = 36.47\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:58<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 542, 2: 105, 3: 18, 4: 3})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 818, hit: 329\n",
      "\n",
      "dev_zero_3 vote precision: 40.22 recall: 33.27 F1 = 36.41\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 543, 2: 108, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] desk [C] service general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 812, hit: 324\n",
      "\n",
      "dev_zero_4 vote precision: 39.90 recall: 32.76 F1 = 35.98\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 540, 2: 110, 3: 16, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 816, hit: 326\n",
      "\n",
      "dev_zero_5 vote precision: 39.95 recall: 32.96 F1 = 36.12\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 541, 2: 110, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 814, hit: 323\n",
      "\n",
      "dev_zero_6 vote precision: 39.68 recall: 32.66 F1 = 35.83\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:58<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 542, 2: 109, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 813, hit: 322\n",
      "\n",
      "dev_zero_7 vote precision: 39.61 recall: 32.56 F1 = 35.74\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 543, 2: 108, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 812, hit: 319\n",
      "\n",
      "dev_zero_8 vote precision: 39.29 recall: 32.25 F1 = 35.42\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 545, 2: 106, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 810, hit: 316\n",
      "\n",
      "dev_zero_9 vote precision: 39.01 recall: 31.95 F1 = 35.13\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 668\n",
      "Total examples = 668\n",
      "668 668 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:57<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 546, 2: 105, 3: 15, 4: 2})\n",
      "gold  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] it [C] restaurant prices [S] great [SSEP] [O] tasty [A] food [C] food quality [S] great\n",
      "pred  [O] fun [A] ambience [C] ambience general [S] great [SSEP] [O] great [A] food [C] food prices [S] great\n",
      "\n",
      "gold  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "pred  [O] saves [A] atmosphere [C] ambience general [S] great [SSEP] [O] disappointing [A] it [C] restaurant general [S] bad\n",
      "\n",
      "gold  [O] good [A] it [C] restaurant general [S] great\n",
      "pred  [O] good [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] adequate [A] fish [C] food style_options [S] bad [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "pred  [O] adequate [A] fish [C] food quality [S] great [SSEP] [O] inexpertly sliced [A] fish [C] food style_options [S] bad\n",
      "\n",
      "gold  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "pred  [O] try [A] sushimi cucumber roll [C] food quality [S] great\n",
      "\n",
      "gold  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "pred  [O] fresh [A] sushi [C] food quality [S] great [SSEP] [O] proportioned [A] sushi [C] food style_options [S] great\n",
      "\n",
      "gold  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad [SSEP] [O] too sweet [A] it [C] food quality [S] bad\n",
      "pred  [O] average [A] food [C] food quality [S] bad [SSEP] [O] too sweet [A] thai fusion stuff [C] food quality [S] bad\n",
      "\n",
      "gold  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad [SSEP] [O] deserves to be shut-down [A] it [C] restaurant general [S] bad\n",
      "pred  [O] terrible [A] management [C] service general [S] bad [SSEP] [O] terrible [A] management [C] service general [S] bad\n",
      "\n",
      "gold  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad [SSEP] [O] overated [A] food [C] food quality [S] bad\n",
      "pred  [O] disappointed [A] service [C] service general [S] bad [SSEP] [O] pricey [A] food [C] food prices [S] bad\n",
      "\n",
      "gold  [O] good [A] quantity [C] food style_options [S] great [SSEP] [O] satisfied [A] quantity [C] food style_options [S] great\n",
      "pred  [O] good [A] quantity [C] food style_options [S] great\n",
      "\n",
      "number of gold spans: 989, predicted spans: 809, hit: 316\n",
      "\n",
      "dev_zero_10 vote precision: 39.06 recall: 31.95 F1 = 35.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "\n",
    "    args.eval_data_split = f'dev_zero_{i}'\n",
    "    print(\"\\n****** Conduct inference on trained checkpoint ******\")\n",
    "    \n",
    "    # initialize the T5 model from previous checkpoint\n",
    "    print(f\"Load trained model from {args.output_dir}\")\n",
    "    print(\n",
    "        'Note that a pretrained model is required and `do_true` should be False'\n",
    "    )\n",
    "\n",
    "    model_path = os.path.join(args.output_dir, \"final2\")\n",
    "\n",
    "    if args.paraphrase:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n",
    "    else:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "    \n",
    "    if args.load_ckpt_name:\n",
    "        ckpt_path = os.path.join(args.output_dir, args.load_ckpt_name)\n",
    "        print(\"Loading ckpt:\", ckpt_path)\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "    log_file_path = os.path.join(args.output_dir, \"result.txt\")\n",
    "    \n",
    "    # compute the performance scores\n",
    "    with open(log_file_path, \"a+\") as f:\n",
    "        config_str = f\"seed: {args.seed}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n",
    "        print(config_str)\n",
    "        f.write(config_str)\n",
    "    \n",
    "        if args.multi_task:\n",
    "            f1s = []\n",
    "            for task in task_data_list:\n",
    "                for data in task_data_list[task]:\n",
    "                    scores = evaluate(model, task, data, data_type=args.eval_data_split)\n",
    "                    print(task, data, scores)\n",
    "                    exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                        args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'],\n",
    "                        scores['f1'])\n",
    "                    f.write(f\"{task}: \\t{data}: \\t{exp_results}\\n\")\n",
    "                    f.flush()\n",
    "                    f1s.append(scores['f1'])\n",
    "            f.write(f\"Average F1: \\t{sum(f1s) / len(f1s)}\\n\")\n",
    "            f.flush()\n",
    "        else:\n",
    "            scores = evaluate(args,\n",
    "                              model,\n",
    "                              args.task,\n",
    "                              args.dataset,\n",
    "                            data_type=args.eval_data_split)\n",
    "    \n",
    "            exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'], scores['f1'])\n",
    "            print()\n",
    "            print(exp_results)\n",
    "            f.write(exp_results + \"\\n\")\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bd9d8-1988-4984-bdc8-7ce26cd42225",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets = [['asqp','rest15'],['asqp','rest16'],['acos','rest16'],['acos','laptop16']]\n",
    "\n",
    "for task_dataset in task_datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4a11254-e271-4445-8043-d22923b177c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/acos/laptop16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 2163\n",
      "Total examples = 2163\n",
      "2163 2163 2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [03:47<00:00,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 1401, 2: 503, 3: 193, 4: 50, 5: 10, 6: 6})\n",
      "gold  [A] wait [O] long [S] bad [C] service general [SSEP] [A] atmosphere [O] raucous [S] bad [C] ambience general [SSEP] [A] it [O] sleek [S] bad [C] restaurant miscellaneous\n",
      "pred  [A] it [O] long [S] great [C] laptop operation_performance [SSEP] [A] it [O] sleek [S] great [C] laptop operation_performance\n",
      "\n",
      "gold  [A] food [O] great [S] great [C] food quality [SSEP] [A] it [O] cheap [S] great [C] restaurant prices\n",
      "pred  [A] it [O] cheap [S] great [C] laptop price [SSEP] [A] it [O] great [S] great [C] laptop general\n",
      "\n",
      "gold  [A] food [O] excellent [S] great [C] food quality\n",
      "pred  [A] food [O] excellent [S] great [C] laptop general\n",
      "\n",
      "gold  [A] glass of wine [O] great [S] great [C] drinks quality\n",
      "pred  [A] wine [O] great [S] great [C] beer general\n",
      "\n",
      "gold  [A] staff [O] friendlier [S] great [C] service general\n",
      "pred  [A] staff [O] friendlier [S] bad [C] support general\n",
      "\n",
      "gold  [A] food [O] bland [S] bad [C] food quality\n",
      "pred  [A] food [O] bland [S] bad [C] laptop quality\n",
      "\n",
      "gold  [A] big wong [O] big ups [S] great [C] restaurant general [SSEP] [A] big wong [O] fine [S] great [C] restaurant general\n",
      "pred  [A] wong [O] big [S] great [C] laptop general [SSEP] [A] establishment [O] fine [S] great [C] hotel general\n",
      "\n",
      "gold  [A] it [O] pleasantly suprised [S] great [C] restaurant general\n",
      "pred  [A] it [O] pleasantly [S] great [C] laptop general\n",
      "\n",
      "gold  [A] mare [O] best [S] great [C] restaurant general\n",
      "pred  [A] mare [O] best [S] great [C] restaurant general\n",
      "\n",
      "gold  [A] it [O] go back [S] great [C] restaurant general\n",
      "pred  [A] it [O] NULL [S] great [C] laptop general\n",
      "\n",
      "number of gold spans: 3547, predicted spans: 3272, hit: 32\n",
      "\n",
      "train-Copy1 vote precision: 0.98 recall: 0.90 F1 = 0.94\n"
     ]
    }
   ],
   "source": [
    "args.task, args.dataset = 'acos','laptop16'\n",
    "args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/top_{args.top_k}_{args.ctrl_token}_data{args.data_ratio}'\n",
    "args.eval_data_split = 'train-Copy1'\n",
    "print(\"\\n****** Conduct inference on trained checkpoint ******\")\n",
    "\n",
    "# initialize the T5 model from previous checkpoint\n",
    "print(f\"Load trained model from {args.output_dir}\")\n",
    "print(\n",
    "    'Note that a pretrained model is required and `do_true` should be False'\n",
    ")\n",
    "\n",
    "model_path = os.path.join(args.output_dir, \"final2\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "\n",
    "if args.load_ckpt_name:\n",
    "    ckpt_path = os.path.join(args.output_dir, args.load_ckpt_name)\n",
    "    print(\"Loading ckpt:\", ckpt_path)\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "log_file_path = os.path.join(args.output_dir, \"result.txt\")\n",
    "\n",
    "# compute the performance scores\n",
    "with open(log_file_path, \"a+\") as f:\n",
    "    config_str = f\"seed: {args.seed}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n",
    "    print(config_str)\n",
    "    f.write(config_str)\n",
    "\n",
    "    if args.multi_task:\n",
    "        f1s = []\n",
    "        for task in task_data_list:\n",
    "            for data in task_data_list[task]:\n",
    "                scores = evaluate(model, task, data, data_type=args.eval_data_split)\n",
    "                print(task, data, scores)\n",
    "                exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                    args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'],\n",
    "                    scores['f1'])\n",
    "                f.write(f\"{task}: \\t{data}: \\t{exp_results}\\n\")\n",
    "                f.flush()\n",
    "                f1s.append(scores['f1'])\n",
    "        f.write(f\"Average F1: \\t{sum(f1s) / len(f1s)}\\n\")\n",
    "        f.flush()\n",
    "    else:\n",
    "        scores = evaluate(args,\n",
    "                          model,\n",
    "                          args.task,\n",
    "                          args.dataset,\n",
    "                        data_type=args.eval_data_split)\n",
    "\n",
    "        exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "            args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'], scores['f1'])\n",
    "        print()\n",
    "        print(exp_results)\n",
    "        f.write(exp_results + \"\\n\")\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa90171-accf-45f9-975a-3cd2a0980052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp",
   "language": "python",
   "name": "mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
